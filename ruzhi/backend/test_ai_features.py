#!/usr/bin/env python3
"""
AIæ™ºèƒ½åŒ–åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•çœŸå®AIæ¨¡å‹é›†æˆã€RAGå¢å¼ºã€ä¸ªæ€§åŒ–å›å¤ç­‰åŠŸèƒ½
"""
import asyncio
import sys
import time
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_real_ai_service():
    """æµ‹è¯•çœŸå®AIæœåŠ¡"""
    print("ğŸ¤– æµ‹è¯•çœŸå®AIæœåŠ¡...")
    
    try:
        from services.real_ai_service import real_ai_service
        
        # æ£€æŸ¥å¯ç”¨æä¾›è€…
        providers = real_ai_service.get_available_providers()
        print(f"   âœ… å¯ç”¨AIæä¾›è€…: {providers}")
        
        # æ£€æŸ¥æä¾›è€…ä¿¡æ¯
        provider_info = real_ai_service.get_provider_info()
        print(f"   ğŸ“Š é»˜è®¤æä¾›è€…: {provider_info['default_provider']}")
        
        # æµ‹è¯•ç®€å•å¯¹è¯
        async def test_chat():
            messages = [
                {"role": "user", "content": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹å„’å®¶æ€æƒ³"}
            ]
            
            result = await real_ai_service.generate_response(messages)
            if result['success']:
                print(f"   âœ… AIå›å¤ç”ŸæˆæˆåŠŸ")
                print(f"   ğŸ“ å›å¤é•¿åº¦: {len(result['content'])}å­—ç¬¦")
                print(f"   â±ï¸  å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.3f}ç§’")
                print(f"   ğŸ”§ ä½¿ç”¨æ¨¡å‹: {result.get('provider', 'unknown')}")
                return True
            else:
                print(f"   âŒ AIå›å¤ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return False
        
        # è¿è¡Œå¼‚æ­¥æµ‹è¯•
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            success = loop.run_until_complete(test_chat())
            return success
        finally:
            loop.close()
            
    except Exception as e:
        print(f"   âŒ çœŸå®AIæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_prompt_builder():
    """æµ‹è¯•æç¤ºè¯æ„å»ºå™¨"""
    print("ğŸ“ æµ‹è¯•æç¤ºè¯æ„å»ºå™¨...")
    
    try:
        from services.prompt_builder import prompt_builder
        from services.character_service import character_service
        
        # è·å–æµ‹è¯•äººç‰©
        character_data = character_service.get_character('confucius')
        if not character_data:
            print("   âŒ æœªæ‰¾åˆ°æµ‹è¯•äººç‰©")
            return False
        
        # æ„å»ºç”¨æˆ·ä¸Šä¸‹æ–‡
        user_context = {
            'emotion_analysis': {
                'primary_emotion': 'sadness',
                'emotion_label': 'æ‚²ä¼¤',
                'confidence': 0.8
            },
            'question_type': 'learning_difficulty',
            'user_level': 'beginner',
            'conversation_context': 'ç”¨æˆ·åœ¨å­¦ä¹ ä¼ ç»Ÿæ–‡åŒ–æ—¶é‡åˆ°å›°éš¾',
            'response_strategy': {
                'tone': 'gentle',
                'empathy_level': 0.8,
                'teaching_style': 'supportive'
            }
        }
        
        # æ„å»ºæç¤ºè¯
        prompt = prompt_builder.build_character_prompt(
            character_data, user_context, []
        )
        
        if prompt and len(prompt) > 100:
            print(f"   âœ… æç¤ºè¯æ„å»ºæˆåŠŸ")
            print(f"   ğŸ“ æç¤ºè¯é•¿åº¦: {len(prompt)}å­—ç¬¦")
            print(f"   ğŸ­ äººç‰©: {character_data['name']}")
            print(f"   ğŸ˜Š æƒ…æ„Ÿé€‚é…: {user_context['emotion_analysis']['emotion_label']}")
            
            # æµ‹è¯•é—®é¢˜ç±»å‹åˆ†æ
            test_messages = [
                "æˆ‘å­¦ä¹ å¤æ–‡å¾ˆå›°éš¾",
                "äººç”Ÿçš„æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ",
                "å¦‚ä½•åœ¨å·¥ä½œä¸­åº”ç”¨å„’å®¶æ€æƒ³ï¼Ÿ",
                "ä»Šå¤©å¿ƒæƒ…å¾ˆä¸å¥½"
            ]
            
            for msg in test_messages:
                question_type = prompt_builder.analyze_question_type(msg)
                print(f"   ğŸ” '{msg}' -> {question_type}")
            
            return True
        else:
            print(f"   âŒ æç¤ºè¯æ„å»ºå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"   âŒ æç¤ºè¯æ„å»ºå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_rag_service():
    """æµ‹è¯•RAGæœåŠ¡"""
    print("ğŸ” æµ‹è¯•RAGæœåŠ¡...")
    
    try:
        from services.rag_service import rag_service
        
        # æµ‹è¯•çŸ¥è¯†æ£€ç´¢
        test_queries = [
            "ä»€ä¹ˆæ˜¯ä»ï¼Ÿ",
            "å­”å­çš„æ•™è‚²æ€æƒ³",
            "é“å®¶çš„è‡ªç„¶è§‚å¿µ",
            "å¦‚ä½•ä¿®èº«å…»æ€§"
        ]
        
        total_knowledge_found = 0
        
        for query in test_queries:
            result = rag_service.enhance_query_with_knowledge(query, 'confucius')
            
            knowledge_count = result['knowledge_count']
            total_knowledge_found += knowledge_count
            
            print(f"   ğŸ” æŸ¥è¯¢: '{query}'")
            print(f"      ğŸ“š æ‰¾åˆ°çŸ¥è¯†: {knowledge_count}ä¸ª")
            print(f"      ğŸ“‹ æ‘˜è¦: {result['knowledge_summary']}")
        
        # æµ‹è¯•çŸ¥è¯†åº“ç»Ÿè®¡
        stats = rag_service.get_knowledge_statistics()
        print(f"   ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡:")
        print(f"      - æ€»çŸ¥è¯†é¡¹: {stats['total_knowledge_items']}")
        print(f"      - äººç‰©: {stats['characters']}ä¸ª")
        print(f"      - ç»å…¸: {stats['classics']}éƒ¨")
        print(f"      - æ¦‚å¿µ: {stats['concepts']}ä¸ª")
        
        if total_knowledge_found > 0:
            print(f"   âœ… RAGæœåŠ¡æ­£å¸¸ï¼Œå…±æ£€ç´¢åˆ°{total_knowledge_found}ä¸ªçŸ¥è¯†ç‚¹")
            return True
        else:
            print(f"   âš ï¸  RAGæœåŠ¡å¯ç”¨ä½†æœªæ£€ç´¢åˆ°çŸ¥è¯†")
            return True
            
    except Exception as e:
        print(f"   âŒ RAGæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_advanced_ai_service():
    """æµ‹è¯•é«˜çº§AIæœåŠ¡"""
    print("ğŸ§  æµ‹è¯•é«˜çº§AIæœåŠ¡...")
    
    try:
        from services.advanced_ai_service import advanced_ai_service
        
        # æµ‹è¯•å¯¹è¯ç”Ÿæˆ
        test_scenarios = [
            {
                'message': 'æˆ‘åœ¨å­¦ä¹ ã€Šè®ºè¯­ã€‹æ—¶æ„Ÿåˆ°å›°æƒ‘ï¼Œå¾ˆå¤šå†…å®¹éƒ½ä¸ç†è§£',
                'character_id': 'confucius',
                'user_id': 'test_user_001',
                'context': {'user_level': 'beginner'},
                'expected_features': ['æƒ…æ„Ÿåˆ†æ', 'å­¦ä¹ æŒ‡å¯¼', 'RAGå¢å¼º']
            },
            {
                'message': 'è¯·è°ˆè°ˆæ‚¨å¯¹"ä»"çš„ç†è§£',
                'character_id': 'confucius', 
                'user_id': 'test_user_002',
                'context': {'user_level': 'intermediate'},
                'expected_features': ['å“²å­¦æ€è¾¨', 'æ¦‚å¿µè§£é‡Š', 'äººç‰©ç‰¹è‰²']
            }
        ]
        
        async def test_scenarios():
            success_count = 0

            for i, scenario in enumerate(test_scenarios, 1):
                print(f"   ğŸ­ åœºæ™¯{i}: {scenario['message'][:20]}...")

                try:
                    result = await advanced_ai_service.generate_advanced_response(
                        user_message=scenario['message'],
                        character_id=scenario['character_id'],
                        user_id=scenario['user_id'],
                        user_context=scenario['context'],
                        stream=False
                    )
                    
                    if result['success']:
                        data = result['data']
                        print(f"      âœ… å›å¤ç”ŸæˆæˆåŠŸ")
                        print(f"      ğŸ“ å›å¤é•¿åº¦: {len(data['response'])}å­—ç¬¦")
                        print(f"      ğŸ˜Š æƒ…æ„Ÿè¯†åˆ«: {data['emotion_analysis']['emotion_label']}")
                        print(f"      ğŸ” é—®é¢˜ç±»å‹: {data['question_type']}")
                        print(f"      ğŸ“š çŸ¥è¯†å¢å¼º: {data['rag_enhancement']['knowledge_used']}ä¸ªçŸ¥è¯†ç‚¹")
                        print(f"      â­ è´¨é‡è¯„åˆ†: {data['quality_assessment']['quality_score']:.2f}")
                        print(f"      â±ï¸  å¤„ç†æ—¶é—´: {data['processing_time']:.3f}ç§’")
                        
                        success_count += 1
                    else:
                        print(f"      âŒ å›å¤ç”Ÿæˆå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        
                except Exception as e:
                    print(f"      âŒ åœºæ™¯æµ‹è¯•å¼‚å¸¸: {e}")
            
            return success_count == len(test_scenarios)
        
        # è¿è¡Œå¼‚æ­¥æµ‹è¯•
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            success = loop.run_until_complete(test_scenarios())
            return success
        finally:
            loop.close()
            
    except Exception as e:
        print(f"   âŒ é«˜çº§AIæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_response_quality():
    """æµ‹è¯•å›å¤è´¨é‡"""
    print("â­ æµ‹è¯•å›å¤è´¨é‡...")
    
    try:
        from services.advanced_ai_service import ResponseQualityFilter
        from services.character_service import character_service
        
        # è·å–æµ‹è¯•äººç‰©
        character_data = character_service.get_character('confucius')
        
        # æµ‹è¯•ä¸åŒè´¨é‡çš„å›å¤
        test_responses = [
            {
                'content': 'å­¦è€Œæ—¶ä¹ ä¹‹ï¼Œä¸äº¦è¯´ä¹ï¼Ÿå­¦ä¹ æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œéœ€è¦ä¸æ–­åœ°å¤ä¹ å’Œå®è·µã€‚åœ¨å­¦ä¹ ä¼ ç»Ÿæ–‡åŒ–æ—¶ï¼Œæˆ‘ä»¬è¦ä¿æŒè°¦é€Šçš„æ€åº¦ï¼Œå¾ªåºæ¸è¿›åœ°ç†è§£å…¶ä¸­çš„æ™ºæ…§ã€‚',
                'expected_score': 0.8
            },
            {
                'content': 'å¥½çš„',
                'expected_score': 0.3
            },
            {
                'content': 'è¿™æ˜¯ä¸€ä¸ªå¾ˆå¤æ‚çš„é—®é¢˜ï¼Œæ¶‰åŠåˆ°å¾ˆå¤šæ–¹é¢çš„å†…å®¹ã€‚' * 50,  # è¿‡é•¿å›å¤
                'expected_score': 0.6
            }
        ]
        
        quality_scores = []
        
        for i, test_case in enumerate(test_responses, 1):
            validation = ResponseQualityFilter.validate_response(
                test_case['content'], character_data
            )
            
            quality_scores.append(validation['quality_score'])
            
            print(f"   ğŸ“ æµ‹è¯•å›å¤{i}:")
            print(f"      âœ… æœ‰æ•ˆæ€§: {validation['is_valid']}")
            print(f"      â­ è´¨é‡è¯„åˆ†: {validation['quality_score']:.2f}")
            print(f"      âš ï¸  é—®é¢˜: {validation['issues']}")
        
        # æµ‹è¯•å¤šæ ·æ€§å¢å¼º
        recent_responses = [
            "å­¦è€Œæ—¶ä¹ ä¹‹ï¼Œä¸äº¦è¯´ä¹ï¼Ÿ",
            "å­¦è€Œæ—¶ä¹ ä¹‹ï¼Œä¸äº¦è¯´ä¹ï¼Ÿ",  # é‡å¤å›å¤
        ]
        
        enhanced = ResponseQualityFilter.enhance_response_diversity(
            "å­¦è€Œæ—¶ä¹ ä¹‹ï¼Œä¸äº¦è¯´ä¹ï¼Ÿ", recent_responses
        )
        
        print(f"   ğŸ”„ å¤šæ ·æ€§å¢å¼ºæµ‹è¯•:")
        print(f"      åŸå›å¤: å­¦è€Œæ—¶ä¹ ä¹‹ï¼Œä¸äº¦è¯´ä¹ï¼Ÿ")
        print(f"      å¢å¼ºå: {enhanced}")
        
        avg_score = sum(quality_scores) / len(quality_scores)
        print(f"   ğŸ“Š å¹³å‡è´¨é‡è¯„åˆ†: {avg_score:.2f}")
        
        return avg_score > 0.5
        
    except Exception as e:
        print(f"   âŒ å›å¤è´¨é‡æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_performance():
    """æµ‹è¯•æ€§èƒ½"""
    print("âš¡ æµ‹è¯•æ€§èƒ½...")
    
    try:
        from services.advanced_ai_service import advanced_ai_service
        
        # æ€§èƒ½æµ‹è¯•å‚æ•°
        test_message = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹å„’å®¶æ€æƒ³çš„æ ¸å¿ƒç†å¿µ"
        character_id = "confucius"
        user_id = "perf_test_user"
        test_count = 5
        
        async def performance_test():
            times = []
            
            for i in range(test_count):
                start_time = time.time()
                
                result = await advanced_ai_service.generate_advanced_response(
                    user_message=test_message,
                    character_id=character_id,
                    user_id=f"{user_id}_{i}",
                    user_context={'user_level': 'beginner'},
                    stream=False
                )
                
                end_time = time.time()
                processing_time = end_time - start_time
                times.append(processing_time)
                
                if result['success']:
                    print(f"   â±ï¸  æµ‹è¯•{i+1}: {processing_time:.3f}ç§’")
                else:
                    print(f"   âŒ æµ‹è¯•{i+1}å¤±è´¥")
            
            if times:
                avg_time = sum(times) / len(times)
                min_time = min(times)
                max_time = max(times)
                
                print(f"   ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
                print(f"      - å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}ç§’")
                print(f"      - æœ€å¿«å“åº”: {min_time:.3f}ç§’")
                print(f"      - æœ€æ…¢å“åº”: {max_time:.3f}ç§’")
                
                return avg_time < 10.0  # æœŸæœ›å¹³å‡å“åº”æ—¶é—´å°äº10ç§’
            
            return False
        
        # è¿è¡Œæ€§èƒ½æµ‹è¯•
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            success = loop.run_until_complete(performance_test())
            return success
        finally:
            loop.close()
            
    except Exception as e:
        print(f"   âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def generate_test_report(results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ AIæ™ºèƒ½åŒ–åŠŸèƒ½æµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)
    
    total_tests = len(results)
    passed_tests = sum(1 for result in results.values() if result)
    failed_tests = total_tests - passed_tests
    
    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"é€šè¿‡: {passed_tests} âœ…")
    print(f"å¤±è´¥: {failed_tests} âŒ")
    print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")
    
    print("\nè¯¦ç»†ç»“æœ:")
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
    
    # åŠŸèƒ½å®Œæˆåº¦è¯„ä¼°
    print("\nğŸ¯ AIæ™ºèƒ½åŒ–åŠŸèƒ½å®Œæˆåº¦è¯„ä¼°:")
    
    if results.get('çœŸå®AIæœåŠ¡', False):
        print("  âœ… çœŸå®AIæ¨¡å‹é›†æˆ: æ”¯æŒå¤šæä¾›è€…ï¼Œè‡ªåŠ¨é™çº§")
    
    if results.get('æç¤ºè¯æ„å»ºå™¨', False):
        print("  âœ… åŠ¨æ€æç¤ºè¯æ„å»º: äººç‰©æ€§æ ¼ã€æƒ…æ„Ÿåˆ†æã€ä¸Šä¸‹æ–‡èåˆ")
    
    if results.get('RAGæœåŠ¡', False):
        print("  âœ… çŸ¥è¯†å¢å¼ºç”Ÿæˆ: æ™ºèƒ½æ£€ç´¢ï¼Œæƒå¨æ€§ä¿è¯")
    
    if results.get('é«˜çº§AIæœåŠ¡', False):
        print("  âœ… ä¸ªæ€§åŒ–å›å¤: å¤šè½®å¯¹è¯ï¼Œæƒ…æ„Ÿæ„ŸçŸ¥ï¼Œè´¨é‡æ§åˆ¶")
    
    if results.get('å›å¤è´¨é‡', False):
        print("  âœ… è´¨é‡ä¿è¯æœºåˆ¶: è‡ªåŠ¨è¯„ä¼°ï¼Œå¤šæ ·æ€§æ§åˆ¶")
    
    if results.get('æ€§èƒ½æµ‹è¯•', False):
        print("  âœ… æ€§èƒ½ä¼˜åŒ–: å“åº”æ—¶é—´ä¼˜åŒ–ï¼Œå¹¶å‘æ”¯æŒ")
    
    # ç”ŸæˆJSONæŠ¥å‘Š
    report = {
        'test_type': 'ai_intelligence_features',
        'timestamp': time.time(),
        'total_tests': total_tests,
        'passed_tests': passed_tests,
        'failed_tests': failed_tests,
        'success_rate': passed_tests/total_tests,
        'results': results,
        'features_implemented': [
            'çœŸå®AIæ¨¡å‹é›†æˆï¼ˆDeepSeekã€OpenAIï¼‰',
            'åŠ¨æ€æç¤ºè¯æ„å»ºç³»ç»Ÿ',
            'RAGçŸ¥è¯†å¢å¼ºç”Ÿæˆ',
            'ä¸ªæ€§åŒ–å›å¤ç­–ç•¥',
            'æƒ…æ„Ÿåˆ†æå’Œé€‚åº”',
            'å¤šè½®å¯¹è¯è®°å¿†ç®¡ç†',
            'å›å¤è´¨é‡è¯„ä¼°å’Œè¿‡æ»¤',
            'æµå¼å¯¹è¯æ”¯æŒ',
            'Webç«¯å’Œå°ç¨‹åºç«¯å®ç°'
        ]
    }
    
    report_file = project_root / 'ai_features_test_report.json'
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return passed_tests == total_tests

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å„’æ™ºé¡¹ç›®AIæ™ºèƒ½åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    print("æµ‹è¯•å†…å®¹: çœŸå®AIé›†æˆã€RAGå¢å¼ºã€ä¸ªæ€§åŒ–å›å¤ã€è´¨é‡æ§åˆ¶")
    print("=" * 60)
    
    # å®šä¹‰æµ‹è¯•å‡½æ•°
    tests = {
        'çœŸå®AIæœåŠ¡': test_real_ai_service,
        'æç¤ºè¯æ„å»ºå™¨': test_prompt_builder,
        'RAGæœåŠ¡': test_rag_service,
        'é«˜çº§AIæœåŠ¡': test_advanced_ai_service,
        'å›å¤è´¨é‡': test_response_quality,
        'æ€§èƒ½æµ‹è¯•': test_performance,
    }
    
    # è¿è¡Œæµ‹è¯•
    results = {}
    for test_name, test_func in tests.items():
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"   âŒ æµ‹è¯• {test_name} å‡ºç°å¼‚å¸¸: {e}")
            results[test_name] = False
        
        print()  # ç©ºè¡Œåˆ†éš”
    
    # ç”ŸæˆæŠ¥å‘Š
    all_passed = generate_test_report(results)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰AIæ™ºèƒ½åŒ–åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ“ˆ AIå¯¹è¯ä½“éªŒæ˜¾è‘—æå‡:")
        print("   - çœŸå®AIæ¨¡å‹é›†æˆï¼Œå›å¤è´¨é‡å¤§å¹…æå‡")
        print("   - RAGçŸ¥è¯†å¢å¼ºï¼Œç¡®ä¿å›å¤å‡†ç¡®æ€§å’Œæƒå¨æ€§")
        print("   - ä¸ªæ€§åŒ–å›å¤ç­–ç•¥ï¼Œé€‚åº”ä¸åŒç”¨æˆ·éœ€æ±‚")
        print("   - æƒ…æ„Ÿæ„ŸçŸ¥å’Œå¤šè½®å¯¹è¯ï¼Œæä¾›è‡ªç„¶äº¤äº’ä½“éªŒ")
        print("   - è´¨é‡æ§åˆ¶æœºåˆ¶ï¼Œä¿è¯å›å¤çš„ä¸€è‡´æ€§å’Œå¤šæ ·æ€§")
        sys.exit(0)
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½å®ç°ã€‚")
        sys.exit(1)

if __name__ == '__main__':
    main()
